{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Recomendations\n",
    "\n",
    "In this project you will make an unsupervised system for music recommendations based on a song.\n",
    "\n",
    "All of the data given to you is from Spotify. For definitions of some of the columns see https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features. The dataset has been partially processed to remove very unusual artists.\n",
    "\n",
    "You will need to go through the entire machine learning process but for unsupervised learning (including big picture, exploration, ...). You will *not* split off a training and testing set. Also, you will not use cross-validation (see an example in a class notebook on how to convince `GridSearchCV` to not use CV). The ultimate goal is to be able to find which 'group' an audio track (which can be music, audio books, or other recordings) belongs to. We also want to make sure that none of the clusters are too small (so that if we ask for a related song, there is a significant amount of variability in the song that we get).\n",
    "\n",
    "To help with making good clusters, you should form clusters for the artists and then integrate that information into each track's data. As with all preprocessing, you should try with and without this step (along with different clusterings of artists).\n",
    "\n",
    "\n",
    "## Notes\n",
    "\n",
    "### Artists Feature\n",
    "\n",
    "The feature `artists` is actually a series of Python lists. To use them is a bit hard, but here are a few examples:\n",
    "  * Get the length of the list for each row:  \n",
    "    `data.artists.str.len()`\n",
    "  * Get the first element of the list for each row:  \n",
    "    `data.artists.apply(lambda artists:artists[0])`\n",
    "  * Get the second element of the list for each row, or None if there is only one:   \n",
    "    `data.artists.apply(lambda artists:artists[1] if len(artists) > 1 else None)`\n",
    "  * To transform each artist in the list based on a dictionary named `trans` that has keys that are artists:  \n",
    "    `data.artists.apply(lambda artists:(trans[artist] for artist in artists))`\n",
    "  * To get the most common value from each list (once converted into something like numbers):  \n",
    "    `data.artists.apply(statistics.mode)`\n",
    "  * To make the list into multiple columns (filled with `None` for rows with fewer than max artists):  \n",
    "    `pd.DataFrame({f'artists_{i}':data.artists.apply(lambda artists:artists[i] if len(artists) > i else None) for i in range(data.artists.str.len().max())})`\n",
    "\n",
    "Also, other methods like `explode()` may be useful.\n",
    "\n",
    "\n",
    "### Scoring\n",
    "\n",
    "To be able to evaluate our model, we will need to use a custom scorer that can be used with `GridSearchCV` and `RandomSearchCV` that prefers clusters that contain pairs used by people in their personal playlists. This playlist data is in the `pairs` data. **This dataset must only be used for scoring.** Additionally, the scorer greatly penalizes having clusters that have less than 200 songs.\n",
    "\n",
    "An example of using it is like:\n",
    "\n",
    "```python\n",
    "GridSearchCV(..., scoring=MusicScorer(data, pairs), ...)\n",
    "```\n",
    "\n",
    "where `data` and `pairs` are the full dataset and the pairs dataset from `load_data()`.\n",
    "\n",
    "\n",
    "### Manual Testing\n",
    "\n",
    "The function `recommendations()` can be used to perform manual testing. It can be called like:\n",
    "\n",
    "```python\n",
    "recommendations(data, clusters, [\"50woGYhAqV3KXvO1LG4zLg\", \"6pmuu4qSz2WrtGkBjUfyuz\", \"3dmqIB2Qxe2XZobw9gXxJ6\"])\n",
    "```\n",
    "\n",
    "where `data` is a `DataFrame` of all of the tracks (minimally the track ids) and `clusters` is a sequence of cluster numbers that line up with `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"\n",
    "    Returns the track data, the artist data, and which pairs of tracks show up\n",
    "    together in playlists. The pairs dataset is extremely large but used as a\n",
    "    sparse matrix. It cannot be directly used.\n",
    "    \"\"\"\n",
    "    data = pd.read_csv('data.csv', converters={'artists':ast.literal_eval})\n",
    "    artists = pd.read_csv('artists.csv')\n",
    "    tracks = np.unique(data.id)\n",
    "    pairs = pd.DataFrame.sparse.from_spmatrix(scipy.sparse.load_npz('track_pairs.npz'), index=tracks, columns=tracks)\n",
    "    return data, artists, pairs\n",
    "\n",
    "\n",
    "def music_score(data, clusters, pairs):\n",
    "    \"\"\"\n",
    "    Scores a set of clusters based on the track data, the clusters they are assigned to,\n",
    "    and the pairs data.\n",
    "    \"\"\"\n",
    "    summation = 0\n",
    "    n_clusters = clusters.max()\n",
    "    for i in range(n_clusters):\n",
    "        tracks = data.id[clusters == i]\n",
    "        sub = pairs.loc[tracks, tracks]\n",
    "        denominator = len(tracks)\n",
    "        if denominator < 200:\n",
    "            denominator = (200*200*200*200)/(denominator*denominator*denominator)\n",
    "        summation += sub.values.sum() / denominator\n",
    "    return summation / n_clusters\n",
    "\n",
    "\n",
    "class MusicScorer:\n",
    "    \"\"\"\n",
    "    This is the actual scorer 'function' to use with `GridSearchCV`.\n",
    "    It is used like:\n",
    "\n",
    "    GridSearchCV(..., scoring=MusicScorer(data, pairs), ...)\n",
    "\n",
    "    where `data` and `pairs` are the full dataset and the pairs\n",
    "    dataset from `load_data()`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, pairs):\n",
    "        self.data = data\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __call__(self, estimator, X, y=None):\n",
    "        # Get the cluster labels\n",
    "        if hasattr(estimator, 'labels_'):\n",
    "            labels = estimator.labels_\n",
    "        elif hasattr(estimator, 'predict'):\n",
    "            labels = estimator.predict(X)\n",
    "        else:\n",
    "            labels = estimator.fit_predict(X)\n",
    "\n",
    "        # Compute the score\n",
    "        return music_score(self.data, labels, self.pairs)\n",
    "\n",
    "\n",
    "def recommendations(all_tracks, clusters, tracks, recommendations_per=5):\n",
    "    \"\"\"\n",
    "    Given the complete data set (`all_tracks` is a DataFrame of track data or is\n",
    "    a series/array of track ids) along with the `clusters` they belong to (a\n",
    "    series/array of cluster numbers), lookup the given tracks (by their ids only),\n",
    "    and return the number of recommendations per each of those tracks.\n",
    "\n",
    "    If this is given a single track (as a string), this will return a single set\n",
    "    of rows from `all_tracks`. If given a list of tracks (as a list of strings),\n",
    "    this will return a list of sets of rows from `all_tracks`. The number of rows\n",
    "    in each set is based on recommendations_per.\n",
    "    \"\"\"\n",
    "    # force types\n",
    "    full_data = len(all_tracks.shape) == 2\n",
    "    all_tracks = pd.DataFrame(all_tracks) if full_data else pd.Series(all_tracks)\n",
    "    all_tracks = all_tracks.reset_index(drop=True)\n",
    "    clusters = pd.Series(clusters).reset_index(drop=True)\n",
    "    single = isinstance(tracks, str)\n",
    "    if single: tracks = [tracks]\n",
    "\n",
    "    # get each track's cluster\n",
    "    matches = all_tracks.id.isin(tracks) if full_data else all_tracks.isin(tracks)\n",
    "    cluster_nums = clusters[matches]\n",
    "\n",
    "    # sample from each cluster\n",
    "    if single:\n",
    "        return all_tracks.loc[clusters[clusters == cluster_nums.iloc[0]].sample(recommendations_per).index]\n",
    "    return [all_tracks.loc[clusters[clusters == cluster].sample(recommendations_per).index] for cluster in cluster_nums]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frame the Problem and Look at the Big Picture \n",
    "1. Define the objective in business terms. \n",
    "    The objective is to make a machine learning model that will give music recommendations based on a song. \n",
    "2. How will your solution be used? \n",
    "    The solution will be used by users of spotify to get song recommendations based on the songs that they are listening to. \n",
    "3. What are the current solutions/workarounds (if any)? \n",
    "    Apple music uses a similar model to give recommendations.\n",
    "4. How should you frame this problem (supervised/unsupervised, online/offline, ...)? \n",
    "    This problem is an unsupervised, offline clustering problem.\n",
    "5. How should performance be measured? Is the performance measure aligned with the business objective? \n",
    "    The performance will be measured using the custom scorer called MusicScorer() using the pairs dataset.\n",
    "6. What would be the minimum performance needed to reach the business objective?\n",
    "    # Each cluster must have more than 200 songs.\n",
    "7. What are comparable problems? Can you reuse experience or tools? \n",
    "    # A comparable problem would be clustering handwritten digets. We could reuse some code from that document with some modifications.\n",
    "8. Is human expertise available? \n",
    "    Human expertise is not availible.\n",
    "9. How would you solve the problem manually? \n",
    "    Recommend popular songs in the same genre. \n",
    "10.  List the assumptions you (or others) have made so far. Verify assumptions if possible. \n",
    "    - The recommended song must be on Spotify.\n",
    "    # Add more here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data \n",
    "1. List the data you need and how much you need \n",
    "    The data needed is songs and artists from Spotify, including their names, artist, genre, etc.\n",
    "2. Find and document where you can get that data \n",
    "    Document was given to us by the client. It was taken from the Spotify API.\n",
    "3. Get access authorizations \n",
    "    Permission recieved by the client.\n",
    "4. Create a workspace (with enough storage space) \n",
    "    This notebook and repository on github.\n",
    "5. Get the data\n",
    "    Data was recieved by the client.\n",
    "6. Convert the data to a format you can easily manipulate (without changing the data itself) \n",
    "    Data was formatted into 3 pandas dataframes.\n",
    "7. Ensure sensitive information is deleted or protected (e.g. anonymized)\n",
    "    There is no sensitive information that needs to be protected or anonymized.\n",
    "8. Check the size and type of data (time series, geographical, ...) \n",
    "    The data dataframe has 61013 data points and 18 different features:\n",
    "    \n",
    "        id: object \n",
    "        name: object \n",
    "        artists: object \n",
    "        year: int64  \n",
    "        duration_ms: int64  \n",
    "        explicit: int64  \n",
    "        popularity: int64  \n",
    "        key: int64  \n",
    "        mode: int64  \n",
    "        tempo: float64\n",
    "        loudness: float64\n",
    "        acousticness: float64\n",
    "        danceability: float64\n",
    "        energy: float64\n",
    "        instrumentalness: float64\n",
    "        liveness: float64\n",
    "        speechiness: float64\n",
    "        valence: float64\n",
    "        \n",
    "    The artists dataframe has 6702 data points and 12 features:\n",
    "\n",
    "        artist: object \n",
    "        count: int64  \n",
    "        popularity: float64\n",
    "        tempo: float64\n",
    "        loudness: float64\n",
    "        acousticness: float64\n",
    "        danceability: float64\n",
    "        energy: float64\n",
    "        instrumentalness: float64\n",
    "        liveness: float64\n",
    "        speechiness: float64\n",
    "        valence: float64\n",
    "        \n",
    "9. Sample a test set, put it aside, and never look at it (no data snooping!) \n",
    "    This is not applicable to unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, artists, pairs = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 61013 entries, 0 to 61012\n",
      "Data columns (total 18 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   id                61013 non-null  object \n",
      " 1   name              61013 non-null  object \n",
      " 2   artists           61013 non-null  object \n",
      " 3   year              61013 non-null  int64  \n",
      " 4   duration_ms       61013 non-null  int64  \n",
      " 5   explicit          61013 non-null  int64  \n",
      " 6   popularity        61013 non-null  int64  \n",
      " 7   key               61013 non-null  int64  \n",
      " 8   mode              61013 non-null  int64  \n",
      " 9   tempo             61013 non-null  float64\n",
      " 10  loudness          61013 non-null  float64\n",
      " 11  acousticness      61013 non-null  float64\n",
      " 12  danceability      61013 non-null  float64\n",
      " 13  energy            61013 non-null  float64\n",
      " 14  instrumentalness  61013 non-null  float64\n",
      " 15  liveness          61013 non-null  float64\n",
      " 16  speechiness       61013 non-null  float64\n",
      " 17  valence           61013 non-null  float64\n",
      "dtypes: float64(9), int64(6), object(3)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6702 entries, 0 to 6701\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   artist            6702 non-null   object \n",
      " 1   count             6702 non-null   int64  \n",
      " 2   popularity        6702 non-null   float64\n",
      " 3   tempo             6702 non-null   float64\n",
      " 4   loudness          6702 non-null   float64\n",
      " 5   acousticness      6702 non-null   float64\n",
      " 6   danceability      6702 non-null   float64\n",
      " 7   energy            6702 non-null   float64\n",
      " 8   instrumentalness  6702 non-null   float64\n",
      " 9   liveness          6702 non-null   float64\n",
      " 10  speechiness       6702 non-null   float64\n",
      " 11  valence           6702 non-null   float64\n",
      "dtypes: float64(10), int64(1), object(1)\n",
      "memory usage: 628.4+ KB\n"
     ]
    }
   ],
   "source": [
    "artists.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data \n",
    "1. Copy the data for exploration, downsampling to a manageable size if necessary. \n",
    "2. Study each attribute and its characteristics: Name; Type (categorical, numerical, \n",
    "bounded, text, structured, ...); % of missing values; Noisiness and type of noise (stochastic, outliers, rounding errors, ...); \n",
    "Usefulness for the task; Type of distribution (Gaussian, uniform, logarithmic, ...) \n",
    "3. For supervised learning tasks, identify the target attribute(s) \n",
    "    Not applicable in this task. (Unsupervised)\n",
    "4. Visualize the data \n",
    "5. Study the correlations between attributes \n",
    "6. Study how you would solve the problem manually \n",
    "7. Identify the promising transformations you may want to apply \n",
    "8. Identify extra data that would be useful (go back to “Get the Data”) \n",
    "9. Document what you have learned \n",
    "    Done Above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data.copy()\n",
    "artists_copy = data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af3f3f87da3ed6054cfd6162ab209d39be2005a8ae75cb4bca1364029f78b035"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
